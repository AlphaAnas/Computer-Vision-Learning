{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:59:58.584354Z","iopub.execute_input":"2025-01-05T20:59:58.584679Z","iopub.status.idle":"2025-01-05T20:59:58.591869Z","shell.execute_reply.started":"2025-01-05T20:59:58.584654Z","shell.execute_reply":"2025-01-05T20:59:58.591127Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import pandas as pd\nimport torch\n\ndata_path_train = \"/kaggle/input/digit-recognizer/train.csv\"\ntrain_data = pd.read_csv(data_path_train)\ntrain_data.head(10)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T20:59:58.593004Z","iopub.execute_input":"2025-01-05T20:59:58.593222Z","iopub.status.idle":"2025-01-05T21:00:00.284695Z","shell.execute_reply.started":"2025-01-05T20:59:58.593204Z","shell.execute_reply":"2025-01-05T21:00:00.283807Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n5      0       0       0       0       0       0       0       0       0   \n6      7       0       0       0       0       0       0       0       0   \n7      3       0       0       0       0       0       0       0       0   \n8      5       0       0       0       0       0       0       0       0   \n9      3       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n5       0  ...         0         0         0         0         0         0   \n6       0  ...         0         0         0         0         0         0   \n7       0  ...         0         0         0         0         0         0   \n8       0  ...         0         0         0         0         0         0   \n9       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n5         0         0         0         0  \n6         0         0         0         0  \n7         0         0         0         0  \n8         0         0         0         0  \n9         0         0         0         0  \n\n[10 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"data_path_test = \"/kaggle/input/digit-recognizer/test.csv\"\ntest_data = pd.read_csv(data_path_test)\ntest_data.head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:00.286175Z","iopub.execute_input":"2025-01-05T21:00:00.286426Z","iopub.status.idle":"2025-01-05T21:00:01.350448Z","shell.execute_reply.started":"2025-01-05T21:00:00.286406Z","shell.execute_reply":"2025-01-05T21:00:01.349576Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n4       0       0       0       0       0       0       0       0       0   \n5       0       0       0       0       0       0       0       0       0   \n6       0       0       0       0       0       0       0       0       0   \n7       0       0       0       0       0       0       0       0       0   \n8       0       0       0       0       0       0       0       0       0   \n9       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n5       0  ...         0         0         0         0         0         0   \n6       0  ...         0         0         0         0         0         0   \n7       0  ...         0         0         0         0         0         0   \n8       0  ...         0         0         0         0         0         0   \n9       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n5         0         0         0         0  \n6         0         0         0         0  \n7         0         0         0         0  \n8         0         0         0         0  \n9         0         0         0         0  \n\n[10 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 784 columns</p>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"train_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:01.351980Z","iopub.execute_input":"2025-01-05T21:00:01.352308Z","iopub.status.idle":"2025-01-05T21:00:01.357029Z","shell.execute_reply.started":"2025-01-05T21:00:01.352279Z","shell.execute_reply":"2025-01-05T21:00:01.356231Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(42000, 785)"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"test_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:01.357958Z","iopub.execute_input":"2025-01-05T21:00:01.358199Z","iopub.status.idle":"2025-01-05T21:00:01.371847Z","shell.execute_reply.started":"2025-01-05T21:00:01.358181Z","shell.execute_reply":"2025-01-05T21:00:01.371188Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(28000, 784)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Ensure correct number of columns\nX_train = train_data.iloc[:, 1:].values  # All rows, columns from 1 to 784 (features)\ny_train = train_data.iloc[:, 0].values  # All rows, column 0 (labels)\n\nX_test = test_data.iloc[:, :784].values  # Ensure only the first 784 columns\ny_test = test_data.iloc[:, 0].values  # Labels (if available)\n\n# Convert to PyTorch tensors and reshape\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32).view(-1, 1, 28, 28)\ny_train_tensor = torch.tensor(y_train, dtype=torch.long)\n\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32).view(-1, 1, 28, 28)\ny_test_tensor = torch.tensor(y_test, dtype=torch.long)\n\n# Normalize pixel values\nX_train_tensor /= 255.0\nX_test_tensor /= 255.0\n\n# Create TensorDataset\ntrain_data = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\ntest_data = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:01.372640Z","iopub.execute_input":"2025-01-05T21:00:01.372906Z","iopub.status.idle":"2025-01-05T21:00:01.507330Z","shell.execute_reply.started":"2025-01-05T21:00:01.372875Z","shell.execute_reply":"2025-01-05T21:00:01.506275Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nloaders = {\n    'train': DataLoader(\n        train_data,\n        batch_size=100,\n        shuffle=True,\n        num_workers=0,\n    ),\n\n    'test':DataLoader(\n        test_data,\n        batch_size=100,\n        shuffle=False,\n        num_workers=0,\n            \n        \n    )\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:01.508244Z","iopub.execute_input":"2025-01-05T21:00:01.508486Z","iopub.status.idle":"2025-01-05T21:00:01.513232Z","shell.execute_reply.started":"2025-01-05T21:00:01.508466Z","shell.execute_reply":"2025-01-05T21:00:01.512271Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"loaders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:01.515928Z","iopub.execute_input":"2025-01-05T21:00:01.516151Z","iopub.status.idle":"2025-01-05T21:00:01.532104Z","shell.execute_reply.started":"2025-01-05T21:00:01.516131Z","shell.execute_reply":"2025-01-05T21:00:01.531289Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"{'train': <torch.utils.data.dataloader.DataLoader at 0x7d1be4ebad10>,\n 'test': <torch.utils.data.dataloader.DataLoader at 0x7d1be4ebb7c0>}"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:01.533546Z","iopub.execute_input":"2025-01-05T21:00:01.533884Z","iopub.status.idle":"2025-01-05T21:00:01.546241Z","shell.execute_reply.started":"2025-01-05T21:00:01.533852Z","shell.execute_reply":"2025-01-05T21:00:01.545524Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"(a) Input: raw pixel values are provided as input. \n(b) Convolutional layer: Input layers translates the results of neuron layer. There is a need to specify the filter to be used. Each filter can only be a 5*5 window that will slide over input data and get pixels with maximum intensities. \n(c) Rectified linear unit [ReLU] layer: provided activation function on the data taken as an image. In the case of backpropagation, ReLU function is used which prevents the values of pixels form changing. \n(d) Pooling layer: Performs a down-sampling operation in volume along the dimensions (width, height). \n(e) Fully connected layer: score class is focused, and a maximum score of the input digits is found\n\nFound in a paper named : Handwritten digit classification using Convolutional Neural Networks","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n#         # First convolutional layer: \n#         # Takes input with 1 channel (grayscale image) and outputs 10 feature maps, \n#         # using a 5x5 kernel to process the input\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  # Input: 1x28x28, Output: 10x24x24 using formula (input_size - 2* (kernel) / padding )+ 1\n#         # Second convolutional layer: \n#         # Takes 10 feature maps from the previous layer and outputs 20 feature maps\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)  # Input: 10x24x24, Output: 20x20x20\n\n        \n#         # Dropout layer: Randomly zeroes some of the features during training \n#         # to prevent overfitting and improve generalization\n        self.conv2_drop = nn.Dropout2d()\n        \n#         # Fully connected layer 1: \n#         # Flattens the output from the convolutional layers to 320 features, \n#         # then reduces it to 50 features\n#         # the reason to 320 is : \n        self.fc1 = nn.Linear(20 * 4 * 4, 50) \n#         # Fully connected layer 2:\n#         # Reduces the 50 features down to 10 (for classification into 10 classes)\n        self.fc2 = nn.Linear(50, 10)  # Output layer with 10 units for 10 classes (digits 0-9)\n#   \n\n    \n    def forward(self, x):\n        x = F.relu(self.conv1(x))  # Output: 10x24x24\n        x = F.max_pool2d(x, 2)     # Max pooling: 10x12x12\n        x = F.relu(self.conv2(x))  # Output: 20x8x8\n        x = F.max_pool2d(x, 2)     # Max pooling: 20x4x4\n        x = self.conv2_drop(x)     # Apply dropout\n        x = x.view(x.size(0), -1)  # Flatten the tensor for fully connected layers\n        x = F.relu(self.fc1(x))    # Fully connected layer\n        x = self.fc2(x)            # Output layer (no softmax because it's handled by CrossEntropyLoss)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:01.546977Z","iopub.execute_input":"2025-01-05T21:00:01.547175Z","iopub.status.idle":"2025-01-05T21:00:01.562619Z","shell.execute_reply.started":"2025-01-05T21:00:01.547159Z","shell.execute_reply":"2025-01-05T21:00:01.561831Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"import torch \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CNN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.005)\nloss_fn= nn.CrossEntropyLoss()\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:01.563365Z","iopub.execute_input":"2025-01-05T21:00:01.563589Z","iopub.status.idle":"2025-01-05T21:00:01.579730Z","shell.execute_reply.started":"2025-01-05T21:00:01.563571Z","shell.execute_reply":"2025-01-05T21:00:01.579046Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"def train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(loaders['train']):\n        # Reshape input\n        data = data.view(-1, 1, 28, 28)  # Reshape to (batch_size, 1, 28, 28)\n        data, target = data.to(device), target.to(device)\n        \n        optimizer.zero_grad()\n        output = model(data)\n        loss = loss_fn(output, target)\n        loss.backward()  # Backpropagation\n        optimizer.step()  # Update parameters\n        \n        if batch_idx % 20 == 0:\n            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)} \"\n                  f\"({100. * batch_idx / len(loaders['train']):.0f}%)]\\tLoss: {loss.item():.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:01.580523Z","iopub.execute_input":"2025-01-05T21:00:01.580731Z","iopub.status.idle":"2025-01-05T21:00:01.594634Z","shell.execute_reply.started":"2025-01-05T21:00:01.580706Z","shell.execute_reply":"2025-01-05T21:00:01.593839Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"\ndef test():\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in loaders['test']:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += loss_fn(output, target).item()\n            pred = output.argmax(dim=1, keepdim=True)\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(loaders['test'].dataset)\n    accuracy = 100. * correct / len(loaders['test'].dataset)\n    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders['test'].dataset)} \"\n          f\"({accuracy:.0f}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:01.595350Z","iopub.execute_input":"2025-01-05T21:00:01.595548Z","iopub.status.idle":"2025-01-05T21:00:01.608538Z","shell.execute_reply.started":"2025-01-05T21:00:01.595513Z","shell.execute_reply":"2025-01-05T21:00:01.607805Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"for epoch in range(1, 11):\n    train(epoch)\n    test()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:01.609447Z","iopub.execute_input":"2025-01-05T21:00:01.609726Z","iopub.status.idle":"2025-01-05T21:00:24.402612Z","shell.execute_reply.started":"2025-01-05T21:00:01.609699Z","shell.execute_reply":"2025-01-05T21:00:24.401722Z"}},"outputs":[{"name":"stdout","text":"Train Epoch: 1 [0/42000 (0%)]\tLoss: 2.327636\nTrain Epoch: 1 [2000/42000 (5%)]\tLoss: 0.957982\nTrain Epoch: 1 [4000/42000 (10%)]\tLoss: 0.736885\nTrain Epoch: 1 [6000/42000 (14%)]\tLoss: 0.502011\nTrain Epoch: 1 [8000/42000 (19%)]\tLoss: 0.313959\nTrain Epoch: 1 [10000/42000 (24%)]\tLoss: 0.432818\nTrain Epoch: 1 [12000/42000 (29%)]\tLoss: 0.249899\nTrain Epoch: 1 [14000/42000 (33%)]\tLoss: 0.482792\nTrain Epoch: 1 [16000/42000 (38%)]\tLoss: 0.331228\nTrain Epoch: 1 [18000/42000 (43%)]\tLoss: 0.319606\nTrain Epoch: 1 [20000/42000 (48%)]\tLoss: 0.167261\nTrain Epoch: 1 [22000/42000 (52%)]\tLoss: 0.182800\nTrain Epoch: 1 [24000/42000 (57%)]\tLoss: 0.134341\nTrain Epoch: 1 [26000/42000 (62%)]\tLoss: 0.292086\nTrain Epoch: 1 [28000/42000 (67%)]\tLoss: 0.138815\nTrain Epoch: 1 [30000/42000 (71%)]\tLoss: 0.074641\nTrain Epoch: 1 [32000/42000 (76%)]\tLoss: 0.201915\nTrain Epoch: 1 [34000/42000 (81%)]\tLoss: 0.183508\nTrain Epoch: 1 [36000/42000 (86%)]\tLoss: 0.218426\nTrain Epoch: 1 [38000/42000 (90%)]\tLoss: 0.163059\nTrain Epoch: 1 [40000/42000 (95%)]\tLoss: 0.093360\n\nTest set: Average loss: 0.1437, Accuracy: 2801/28000 (10%)\nTrain Epoch: 2 [0/42000 (0%)]\tLoss: 0.154317\nTrain Epoch: 2 [2000/42000 (5%)]\tLoss: 0.246284\nTrain Epoch: 2 [4000/42000 (10%)]\tLoss: 0.126276\nTrain Epoch: 2 [6000/42000 (14%)]\tLoss: 0.053023\nTrain Epoch: 2 [8000/42000 (19%)]\tLoss: 0.121673\nTrain Epoch: 2 [10000/42000 (24%)]\tLoss: 0.125222\nTrain Epoch: 2 [12000/42000 (29%)]\tLoss: 0.163027\nTrain Epoch: 2 [14000/42000 (33%)]\tLoss: 0.089157\nTrain Epoch: 2 [16000/42000 (38%)]\tLoss: 0.072273\nTrain Epoch: 2 [18000/42000 (43%)]\tLoss: 0.226335\nTrain Epoch: 2 [20000/42000 (48%)]\tLoss: 0.179667\nTrain Epoch: 2 [22000/42000 (52%)]\tLoss: 0.185723\nTrain Epoch: 2 [24000/42000 (57%)]\tLoss: 0.172916\nTrain Epoch: 2 [26000/42000 (62%)]\tLoss: 0.075310\nTrain Epoch: 2 [28000/42000 (67%)]\tLoss: 0.131919\nTrain Epoch: 2 [30000/42000 (71%)]\tLoss: 0.221715\nTrain Epoch: 2 [32000/42000 (76%)]\tLoss: 0.087948\nTrain Epoch: 2 [34000/42000 (81%)]\tLoss: 0.212394\nTrain Epoch: 2 [36000/42000 (86%)]\tLoss: 0.164867\nTrain Epoch: 2 [38000/42000 (90%)]\tLoss: 0.120369\nTrain Epoch: 2 [40000/42000 (95%)]\tLoss: 0.137037\n\nTest set: Average loss: 0.1450, Accuracy: 2786/28000 (10%)\nTrain Epoch: 3 [0/42000 (0%)]\tLoss: 0.115625\nTrain Epoch: 3 [2000/42000 (5%)]\tLoss: 0.032158\nTrain Epoch: 3 [4000/42000 (10%)]\tLoss: 0.048912\nTrain Epoch: 3 [6000/42000 (14%)]\tLoss: 0.037059\nTrain Epoch: 3 [8000/42000 (19%)]\tLoss: 0.058761\nTrain Epoch: 3 [10000/42000 (24%)]\tLoss: 0.073981\nTrain Epoch: 3 [12000/42000 (29%)]\tLoss: 0.048528\nTrain Epoch: 3 [14000/42000 (33%)]\tLoss: 0.200841\nTrain Epoch: 3 [16000/42000 (38%)]\tLoss: 0.022039\nTrain Epoch: 3 [18000/42000 (43%)]\tLoss: 0.229470\nTrain Epoch: 3 [20000/42000 (48%)]\tLoss: 0.070697\nTrain Epoch: 3 [22000/42000 (52%)]\tLoss: 0.159012\nTrain Epoch: 3 [24000/42000 (57%)]\tLoss: 0.192726\nTrain Epoch: 3 [26000/42000 (62%)]\tLoss: 0.140955\nTrain Epoch: 3 [28000/42000 (67%)]\tLoss: 0.145063\nTrain Epoch: 3 [30000/42000 (71%)]\tLoss: 0.200703\nTrain Epoch: 3 [32000/42000 (76%)]\tLoss: 0.030907\nTrain Epoch: 3 [34000/42000 (81%)]\tLoss: 0.046217\nTrain Epoch: 3 [36000/42000 (86%)]\tLoss: 0.038454\nTrain Epoch: 3 [38000/42000 (90%)]\tLoss: 0.054134\nTrain Epoch: 3 [40000/42000 (95%)]\tLoss: 0.053579\n\nTest set: Average loss: 0.1727, Accuracy: 2792/28000 (10%)\nTrain Epoch: 4 [0/42000 (0%)]\tLoss: 0.257579\nTrain Epoch: 4 [2000/42000 (5%)]\tLoss: 0.179916\nTrain Epoch: 4 [4000/42000 (10%)]\tLoss: 0.168008\nTrain Epoch: 4 [6000/42000 (14%)]\tLoss: 0.101675\nTrain Epoch: 4 [8000/42000 (19%)]\tLoss: 0.108236\nTrain Epoch: 4 [10000/42000 (24%)]\tLoss: 0.024332\nTrain Epoch: 4 [12000/42000 (29%)]\tLoss: 0.100135\nTrain Epoch: 4 [14000/42000 (33%)]\tLoss: 0.147487\nTrain Epoch: 4 [16000/42000 (38%)]\tLoss: 0.056804\nTrain Epoch: 4 [18000/42000 (43%)]\tLoss: 0.151546\nTrain Epoch: 4 [20000/42000 (48%)]\tLoss: 0.041109\nTrain Epoch: 4 [22000/42000 (52%)]\tLoss: 0.099117\nTrain Epoch: 4 [24000/42000 (57%)]\tLoss: 0.101847\nTrain Epoch: 4 [26000/42000 (62%)]\tLoss: 0.067589\nTrain Epoch: 4 [28000/42000 (67%)]\tLoss: 0.060602\nTrain Epoch: 4 [30000/42000 (71%)]\tLoss: 0.114640\nTrain Epoch: 4 [32000/42000 (76%)]\tLoss: 0.120909\nTrain Epoch: 4 [34000/42000 (81%)]\tLoss: 0.142382\nTrain Epoch: 4 [36000/42000 (86%)]\tLoss: 0.162000\nTrain Epoch: 4 [38000/42000 (90%)]\tLoss: 0.071027\nTrain Epoch: 4 [40000/42000 (95%)]\tLoss: 0.051651\n\nTest set: Average loss: 0.1642, Accuracy: 2763/28000 (10%)\nTrain Epoch: 5 [0/42000 (0%)]\tLoss: 0.089836\nTrain Epoch: 5 [2000/42000 (5%)]\tLoss: 0.111522\nTrain Epoch: 5 [4000/42000 (10%)]\tLoss: 0.051488\nTrain Epoch: 5 [6000/42000 (14%)]\tLoss: 0.030467\nTrain Epoch: 5 [8000/42000 (19%)]\tLoss: 0.105748\nTrain Epoch: 5 [10000/42000 (24%)]\tLoss: 0.082829\nTrain Epoch: 5 [12000/42000 (29%)]\tLoss: 0.116522\nTrain Epoch: 5 [14000/42000 (33%)]\tLoss: 0.174368\nTrain Epoch: 5 [16000/42000 (38%)]\tLoss: 0.224357\nTrain Epoch: 5 [18000/42000 (43%)]\tLoss: 0.071762\nTrain Epoch: 5 [20000/42000 (48%)]\tLoss: 0.016113\nTrain Epoch: 5 [22000/42000 (52%)]\tLoss: 0.186936\nTrain Epoch: 5 [24000/42000 (57%)]\tLoss: 0.045983\nTrain Epoch: 5 [26000/42000 (62%)]\tLoss: 0.070853\nTrain Epoch: 5 [28000/42000 (67%)]\tLoss: 0.070654\nTrain Epoch: 5 [30000/42000 (71%)]\tLoss: 0.140401\nTrain Epoch: 5 [32000/42000 (76%)]\tLoss: 0.039233\nTrain Epoch: 5 [34000/42000 (81%)]\tLoss: 0.112869\nTrain Epoch: 5 [36000/42000 (86%)]\tLoss: 0.225004\nTrain Epoch: 5 [38000/42000 (90%)]\tLoss: 0.050954\nTrain Epoch: 5 [40000/42000 (95%)]\tLoss: 0.137118\n\nTest set: Average loss: 0.1617, Accuracy: 2769/28000 (10%)\nTrain Epoch: 6 [0/42000 (0%)]\tLoss: 0.061938\nTrain Epoch: 6 [2000/42000 (5%)]\tLoss: 0.034102\nTrain Epoch: 6 [4000/42000 (10%)]\tLoss: 0.206931\nTrain Epoch: 6 [6000/42000 (14%)]\tLoss: 0.244866\nTrain Epoch: 6 [8000/42000 (19%)]\tLoss: 0.037079\nTrain Epoch: 6 [10000/42000 (24%)]\tLoss: 0.044622\nTrain Epoch: 6 [12000/42000 (29%)]\tLoss: 0.212259\nTrain Epoch: 6 [14000/42000 (33%)]\tLoss: 0.170309\nTrain Epoch: 6 [16000/42000 (38%)]\tLoss: 0.090455\nTrain Epoch: 6 [18000/42000 (43%)]\tLoss: 0.092796\nTrain Epoch: 6 [20000/42000 (48%)]\tLoss: 0.080018\nTrain Epoch: 6 [22000/42000 (52%)]\tLoss: 0.163111\nTrain Epoch: 6 [24000/42000 (57%)]\tLoss: 0.131912\nTrain Epoch: 6 [26000/42000 (62%)]\tLoss: 0.038825\nTrain Epoch: 6 [28000/42000 (67%)]\tLoss: 0.078286\nTrain Epoch: 6 [30000/42000 (71%)]\tLoss: 0.053137\nTrain Epoch: 6 [32000/42000 (76%)]\tLoss: 0.039991\nTrain Epoch: 6 [34000/42000 (81%)]\tLoss: 0.046851\nTrain Epoch: 6 [36000/42000 (86%)]\tLoss: 0.085867\nTrain Epoch: 6 [38000/42000 (90%)]\tLoss: 0.050645\nTrain Epoch: 6 [40000/42000 (95%)]\tLoss: 0.076777\n\nTest set: Average loss: 0.1860, Accuracy: 2788/28000 (10%)\nTrain Epoch: 7 [0/42000 (0%)]\tLoss: 0.044134\nTrain Epoch: 7 [2000/42000 (5%)]\tLoss: 0.065966\nTrain Epoch: 7 [4000/42000 (10%)]\tLoss: 0.072399\nTrain Epoch: 7 [6000/42000 (14%)]\tLoss: 0.093163\nTrain Epoch: 7 [8000/42000 (19%)]\tLoss: 0.129420\nTrain Epoch: 7 [10000/42000 (24%)]\tLoss: 0.096250\nTrain Epoch: 7 [12000/42000 (29%)]\tLoss: 0.080876\nTrain Epoch: 7 [14000/42000 (33%)]\tLoss: 0.018166\nTrain Epoch: 7 [16000/42000 (38%)]\tLoss: 0.179544\nTrain Epoch: 7 [18000/42000 (43%)]\tLoss: 0.103457\nTrain Epoch: 7 [20000/42000 (48%)]\tLoss: 0.098176\nTrain Epoch: 7 [22000/42000 (52%)]\tLoss: 0.141299\nTrain Epoch: 7 [24000/42000 (57%)]\tLoss: 0.033207\nTrain Epoch: 7 [26000/42000 (62%)]\tLoss: 0.035741\nTrain Epoch: 7 [28000/42000 (67%)]\tLoss: 0.094853\nTrain Epoch: 7 [30000/42000 (71%)]\tLoss: 0.088463\nTrain Epoch: 7 [32000/42000 (76%)]\tLoss: 0.127029\nTrain Epoch: 7 [34000/42000 (81%)]\tLoss: 0.047857\nTrain Epoch: 7 [36000/42000 (86%)]\tLoss: 0.125129\nTrain Epoch: 7 [38000/42000 (90%)]\tLoss: 0.084981\nTrain Epoch: 7 [40000/42000 (95%)]\tLoss: 0.158053\n\nTest set: Average loss: 0.1862, Accuracy: 2786/28000 (10%)\nTrain Epoch: 8 [0/42000 (0%)]\tLoss: 0.034915\nTrain Epoch: 8 [2000/42000 (5%)]\tLoss: 0.044736\nTrain Epoch: 8 [4000/42000 (10%)]\tLoss: 0.084343\nTrain Epoch: 8 [6000/42000 (14%)]\tLoss: 0.031284\nTrain Epoch: 8 [8000/42000 (19%)]\tLoss: 0.036606\nTrain Epoch: 8 [10000/42000 (24%)]\tLoss: 0.351097\nTrain Epoch: 8 [12000/42000 (29%)]\tLoss: 0.047481\nTrain Epoch: 8 [14000/42000 (33%)]\tLoss: 0.045801\nTrain Epoch: 8 [16000/42000 (38%)]\tLoss: 0.034776\nTrain Epoch: 8 [18000/42000 (43%)]\tLoss: 0.088537\nTrain Epoch: 8 [20000/42000 (48%)]\tLoss: 0.021978\nTrain Epoch: 8 [22000/42000 (52%)]\tLoss: 0.064581\nTrain Epoch: 8 [24000/42000 (57%)]\tLoss: 0.034935\nTrain Epoch: 8 [26000/42000 (62%)]\tLoss: 0.032466\nTrain Epoch: 8 [28000/42000 (67%)]\tLoss: 0.097319\nTrain Epoch: 8 [30000/42000 (71%)]\tLoss: 0.037923\nTrain Epoch: 8 [32000/42000 (76%)]\tLoss: 0.066870\nTrain Epoch: 8 [34000/42000 (81%)]\tLoss: 0.049267\nTrain Epoch: 8 [36000/42000 (86%)]\tLoss: 0.078962\nTrain Epoch: 8 [38000/42000 (90%)]\tLoss: 0.033915\nTrain Epoch: 8 [40000/42000 (95%)]\tLoss: 0.093536\n\nTest set: Average loss: 0.1840, Accuracy: 2769/28000 (10%)\nTrain Epoch: 9 [0/42000 (0%)]\tLoss: 0.042531\nTrain Epoch: 9 [2000/42000 (5%)]\tLoss: 0.055661\nTrain Epoch: 9 [4000/42000 (10%)]\tLoss: 0.213768\nTrain Epoch: 9 [6000/42000 (14%)]\tLoss: 0.065931\nTrain Epoch: 9 [8000/42000 (19%)]\tLoss: 0.078330\nTrain Epoch: 9 [10000/42000 (24%)]\tLoss: 0.061493\nTrain Epoch: 9 [12000/42000 (29%)]\tLoss: 0.094630\nTrain Epoch: 9 [14000/42000 (33%)]\tLoss: 0.032761\nTrain Epoch: 9 [16000/42000 (38%)]\tLoss: 0.150791\nTrain Epoch: 9 [18000/42000 (43%)]\tLoss: 0.081502\nTrain Epoch: 9 [20000/42000 (48%)]\tLoss: 0.031116\nTrain Epoch: 9 [22000/42000 (52%)]\tLoss: 0.081713\nTrain Epoch: 9 [24000/42000 (57%)]\tLoss: 0.067475\nTrain Epoch: 9 [26000/42000 (62%)]\tLoss: 0.150054\nTrain Epoch: 9 [28000/42000 (67%)]\tLoss: 0.064843\nTrain Epoch: 9 [30000/42000 (71%)]\tLoss: 0.117973\nTrain Epoch: 9 [32000/42000 (76%)]\tLoss: 0.089187\nTrain Epoch: 9 [34000/42000 (81%)]\tLoss: 0.043417\nTrain Epoch: 9 [36000/42000 (86%)]\tLoss: 0.046127\nTrain Epoch: 9 [38000/42000 (90%)]\tLoss: 0.031612\nTrain Epoch: 9 [40000/42000 (95%)]\tLoss: 0.083569\n\nTest set: Average loss: 0.1671, Accuracy: 2797/28000 (10%)\nTrain Epoch: 10 [0/42000 (0%)]\tLoss: 0.074941\nTrain Epoch: 10 [2000/42000 (5%)]\tLoss: 0.122791\nTrain Epoch: 10 [4000/42000 (10%)]\tLoss: 0.081250\nTrain Epoch: 10 [6000/42000 (14%)]\tLoss: 0.060066\nTrain Epoch: 10 [8000/42000 (19%)]\tLoss: 0.073776\nTrain Epoch: 10 [10000/42000 (24%)]\tLoss: 0.054245\nTrain Epoch: 10 [12000/42000 (29%)]\tLoss: 0.076068\nTrain Epoch: 10 [14000/42000 (33%)]\tLoss: 0.059438\nTrain Epoch: 10 [16000/42000 (38%)]\tLoss: 0.093265\nTrain Epoch: 10 [18000/42000 (43%)]\tLoss: 0.035240\nTrain Epoch: 10 [20000/42000 (48%)]\tLoss: 0.110565\nTrain Epoch: 10 [22000/42000 (52%)]\tLoss: 0.067297\nTrain Epoch: 10 [24000/42000 (57%)]\tLoss: 0.030069\nTrain Epoch: 10 [26000/42000 (62%)]\tLoss: 0.148616\nTrain Epoch: 10 [28000/42000 (67%)]\tLoss: 0.025754\nTrain Epoch: 10 [30000/42000 (71%)]\tLoss: 0.102135\nTrain Epoch: 10 [32000/42000 (76%)]\tLoss: 0.098500\nTrain Epoch: 10 [34000/42000 (81%)]\tLoss: 0.133713\nTrain Epoch: 10 [36000/42000 (86%)]\tLoss: 0.104832\nTrain Epoch: 10 [38000/42000 (90%)]\tLoss: 0.043245\nTrain Epoch: 10 [40000/42000 (95%)]\tLoss: 0.043304\n\nTest set: Average loss: 0.1861, Accuracy: 2764/28000 (10%)\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"def generate_submission(model, test_loader, output_file=\"submission.csv\"):\n    \"\"\"\n    Generate predictions for the test set and save them in a CSV file for Kaggle submission.\n    Parameters:\n        model (torch.nn.Module): Trained PyTorch model.\n        test_loader (DataLoader): DataLoader for the test dataset.\n        output_file (str): Name of the output CSV file.\n    \"\"\"\n    model.eval()  # Set the model to evaluation mode\n    predictions = []\n    \n    with torch.no_grad():\n        for data, _ in test_loader:  # DataLoader returns (data, _), but labels are not needed\n            data = data.to(device)\n            output = model(data)\n            preds = output.argmax(dim=1, keepdim=False)  # Get the predicted class\n            predictions.extend(preds.cpu().numpy())  # Move predictions to CPU and store them\n\n    # Create the submission DataFrame\n    submission = pd.DataFrame({\n        \"ImageId\": range(1, len(predictions) + 1),  # Image IDs start at 1\n        \"Label\": predictions  # Predicted labels\n    })\n\n    submission.to_csv(output_file, index=False)  # Save submission file\n    print(f\"Submission file saved as {output_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:24.403542Z","iopub.execute_input":"2025-01-05T21:00:24.403866Z","iopub.status.idle":"2025-01-05T21:00:24.409204Z","shell.execute_reply.started":"2025-01-05T21:00:24.403834Z","shell.execute_reply":"2025-01-05T21:00:24.408393Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"generate_submission(model, loaders['test'], \"submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-05T21:00:24.409911Z","iopub.execute_input":"2025-01-05T21:00:24.410095Z","iopub.status.idle":"2025-01-05T21:00:24.975400Z","shell.execute_reply.started":"2025-01-05T21:00:24.410079Z","shell.execute_reply":"2025-01-05T21:00:24.974703Z"}},"outputs":[{"name":"stdout","text":"Submission file saved as submission.csv\n","output_type":"stream"}],"execution_count":47}]}